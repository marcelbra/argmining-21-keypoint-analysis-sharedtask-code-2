{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "\n",
    "- Import model\n",
    "    Import the trained model instead of training from scratch\n",
    "    - See cell 3\n",
    "    - The basic idea is:\n",
    "        - initialize the model as it was trained, in sbert_training the definition can be found\n",
    "        - load the weights into the model (by whichever means)\n",
    "        - The trained model is here: https://drive.google.com/drive/folders/1qgGdoNMUcyQivTtu5udzGcQB8SFgxm-M?usp=sharing\n",
    "\n",
    "- Changing loss to score\n",
    "    Right now the metric is the loss because I could not yet find a way to retrieve the score. One can interpret\n",
    "    the loss as the inverse score, so the lesser the loss, the better. To better compare we have to change that to a score.\n",
    "\n",
    "- Leave-one-out\n",
    "    Extend the method / dataloader with all instead of only the dummy sample\n",
    "    - The dev data can be found in /new_KPA/argmining-21-keypoint-analysis-sharedtask-code/data/kpm_data\n",
    "    - There could be two ways to approach this:\n",
    "        - Interpret the gold standard:\n",
    "            - Iterate over kps in key_points_dev.csv and grab the respective argument from arguments_dev.csv\n",
    "        - Let the model decide what is the right arg\n",
    "            - Iterate over all args, computer score with each kp and save argmax\n",
    "    - What needs to be added is for each InputExample save the word we dropped so we can access it during\n",
    "      entailment computing. For this copy InputExample from SentenceBert and modify class, save word to later access\n",
    "\n",
    "- SHAP\n",
    "    - I have prepared the model for inference (except the loss thing) so next SHAP can be implemented\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer, InputExample, LoggingHandler, losses, models, util\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import sys\n",
    "from nltk import word_tokenize\n",
    "sys.path.insert(0, \"/home/marcelbraasch/PycharmProjects/new_KPA/argmining-21-keypoint-analysis-sharedtask-code/code/src-py\")\n",
    "import sbert_training\n",
    "work_tokenizer = word_tokenize\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "!source /home/marcelbraasch/PycharmProjects/new_KPA/venv/bin/activate\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = sbert_training.train_model('/home/marcelbraasch/PycharmProjects/new_KPA/argmining-21-keypoint-analysis-sharedtask-code/data/siamese-data/',\n",
    "                           \"/home/marcelbraasch/PycharmProjects/new_KPA/argmining-21-keypoint-analysis-sharedtask-code/data/kpm_data\",\n",
    "                           'dev',\n",
    "                           \"/home/marcelbraasch/PycharmProjects/new_KPA/argmining-21-keypoint-analysis-sharedtask-code/code/siamese-models\",\n",
    "                           'roberta-base',\n",
    "                           model_suffix='contrastive-10-epochs',\n",
    "                           data_file_suffix='contrastive',\n",
    "                           num_epochs=1, max_seq_length=70, add_special_token=True, train_batch_size=32, loss='ContrastiveLoss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# def load_model():\n",
    "#     max_seq_length = 70\n",
    "#     model_name = 'distilbert-base-uncased'\n",
    "#     word_embedding_model = models.Transformer(model_name)\n",
    "#     word_embedding_model.max_seq_length = max_seq_length\n",
    "#     word_embedding_model.tokenizer.add_tokens(['<SEP>'], special_tokens=True)\n",
    "#     word_embedding_model.auto_model.resize_token_embeddings(len(word_embedding_model.tokenizer))\n",
    "#     pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "#                                    pooling_mode_mean_tokens=True,\n",
    "#                                    pooling_mode_cls_token=False,\n",
    "#                                    pooling_mode_max_tokens=False)\n",
    "#     model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "#     return model\n",
    "\n",
    "# config = BertConfig.from_json_file(\"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/model/config.json\")\n",
    "# model = TFBertModel.from_pretrained('/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/model/my_pytorch_model.bin', from_pt=True, config=config)\n",
    "\n",
    "# path = \"./siamese_state_dict_2.pt\"\n",
    "# state_dict = torch.load(path)[\"state_dict\"]\n",
    "# model = load_model()\n",
    "# model.load_state_dict(state_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_data_for_leave_one_out(path):\n",
    "    \"\"\"\n",
    "    Creates a nested list of data.\n",
    "    For each arg-kp pair we create no_of_words_in_kp InputExamples.\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    # Here all the data should be loaded instead of only 1 test sample\n",
    "    for _ in range(1):\n",
    "        topic = \"We should abandon the use of school uniform\"\n",
    "        arg = \"A real education is about giving students the tools to learn, think, and express themselves; dictating to them what to wear sends a strong message that we don't trust them to think on their own.\"\n",
    "        kp = \"School uniform is harming the student's self expression\"\n",
    "        label = 1\n",
    "        sample = [InputExample(texts=[arg, kp + \" <SEP> \" + topic], label=label)]\n",
    "        words = work_tokenizer(kp)\n",
    "        for i in range(len(words)):\n",
    "            new_kp = copy.deepcopy(words)\n",
    "            new_kp.pop(i)\n",
    "            new_kp_topic = \" \".join(new_kp)\n",
    "            dropped_word = words[i]\n",
    "            sample.append(InputExample(texts=[arg, new_kp_topic], label=label))\n",
    "        samples.append(sample)\n",
    "    return samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_dataloader(examples, model):\n",
    "    dataloader = DataLoader(examples, shuffle=False, batch_size=1)\n",
    "    dataloader.collate_fn = model.smart_batching_collate\n",
    "    return iter(dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_dataloaders_for_leave_one_out(data, model):\n",
    "    dataloaders = []\n",
    "    for sample in data:\n",
    "        # sample has no_of_words_in_kp examples in it\n",
    "        dataloader = DataLoader(sample, shuffle=False, batch_size=1)\n",
    "        dataloader.collate_fn = model.smart_batching_collate\n",
    "        dataloaders.append(dataloader)\n",
    "    return dataloaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def prepare_model_for_inference(model):\n",
    "    model = losses.ContrastiveLoss(model)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def compute_entailment(model, features, labels):\n",
    "    return float((1 - model(features, labels)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-18 22:06:29 - Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_29992/1855964181.py\", line 26, in <module>\n",
      "    run_methods(model)\n",
      "  File \"/tmp/ipykernel_29992/1855964181.py\", line 23, in run_methods\n",
      "    s = 0\n",
      "  File \"/tmp/ipykernel_29992/1855964181.py\", line 23, in run_methods\n",
      "    s = 0\n",
      "  File \"/home/marcelbraasch/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\", line 747, in trace_dispatch\n",
      "    self.do_wait_suspend(thread, frame, event, arg)\n",
      "  File \"/home/marcelbraasch/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\", line 144, in do_wait_suspend\n",
      "    self._args[0].do_wait_suspend(*args, **kwargs)\n",
      "  File \"/home/marcelbraasch/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/pydevd.py\", line 1147, in do_wait_suspend\n",
      "    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)\n",
      "  File \"/home/marcelbraasch/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/pydevd.py\", line 1162, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 745, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/torch/backends/__init__.py\", line 46, in __getattr__\n",
      "    def __getattr__(self, attr):\n",
      "KeyboardInterrupt\n",
      "2022-01-18 22:06:29 - \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_29992/1855964181.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m \u001B[0mrun_methods\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_29992/1855964181.py\u001B[0m in \u001B[0;36mrun_methods\u001B[0;34m(model)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m     \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_29992/1855964181.py\u001B[0m in \u001B[0;36mrun_methods\u001B[0;34m(model)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m     \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001B[0m in \u001B[0;36mtrace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    746\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0minfo\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpydev_state\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mSTATE_SUSPEND\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 747\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    748\u001B[0m                     \u001B[0;31m# No need to reset frame.f_trace to keep the same trace function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 144\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1146\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1162\u001B[0;31m                 \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2076\u001B[0m                         \u001B[0;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2077\u001B[0;31m                         \u001B[0mstb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2078\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2077\u001B[0m                         \u001B[0mstb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2078\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2079\u001B[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[0m\u001B[1;32m   2080\u001B[0m                                             value, tb, tb_offset=tb_offset)\n\u001B[1;32m   2081\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1365\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1367\u001B[0;31m         return FormattedTB.structured_traceback(\n\u001B[0m\u001B[1;32m   1368\u001B[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[1;32m   1369\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1265\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose_modes\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1266\u001B[0m             \u001B[0;31m# Verbose modes need a full traceback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1267\u001B[0;31m             return VerboseTB.structured_traceback(\n\u001B[0m\u001B[1;32m   1268\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1269\u001B[0m             )\n",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1122\u001B[0m         \u001B[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1123\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1124\u001B[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[0m\u001B[1;32m   1125\u001B[0m                                                                tb_offset)\n\u001B[1;32m   1126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1081\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1082\u001B[0;31m         \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1083\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1084\u001B[0m         \u001B[0mframes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[0;34m(etype, value, records)\u001B[0m\n\u001B[1;32m    380\u001B[0m     \u001B[0;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    381\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 382\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    383\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    384\u001B[0m     \u001B[0;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "def run_methods(model):\n",
    "    path = \"./test_path/\"\n",
    "    loss_model = prepare_model_for_inference(model)\n",
    "    # methods = [leave_one_out]\n",
    "\n",
    "    # Mask one\n",
    "    data = get_data_for_leave_one_out(path)\n",
    "    dataloaders = get_dataloaders_for_leave_one_out(data, model)\n",
    "    for dataloader in dataloaders:\n",
    "        scores = []\n",
    "        dropped = []\n",
    "        words = None\n",
    "        for i, (features, labels) in enumerate(dataloader):\n",
    "            scores.append(compute_entailment(loss_model, features, labels))\n",
    "            if not i:\n",
    "                dropped.append(\"Reference\")\n",
    "                words = [model.tokenizer.convert_ids_to_tokens(x) for x in features[1][\"input_ids\"][0].tolist()]\n",
    "                sep_index = words.index(\"<SEP>\")\n",
    "                words = words[1:sep_index]\n",
    "            else:\n",
    "                dropped.append(words.pop(0))\n",
    "\n",
    "run_methods(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "############################################################\n",
    "############################################################\n",
    "################# CODE GRAVEYARD ###########################\n",
    "############################################################\n",
    "############################################################\n",
    "\n",
    "# def get_backbone_model_and_tokenizer():\n",
    "#     name = 'roberta-base'\n",
    "#     backbone = models.Transformer(name)\n",
    "#     backbone.max_seq_length = 70\n",
    "#     backbone.tokenizer.add_tokens(['<SEP>'], special_tokens=True)\n",
    "#     backbone.auto_model.resize_token_embeddings(len(backbone.tokenizer))\n",
    "#     return backbone, backbone.tokenizer\n",
    "\n",
    "            # modified_features = [{\"input_ids\": features[0][\"input_ids\"],\n",
    "            #                       \"attention_mask\": features[0][\"attention_mask\"]},\n",
    "            #                      {\"input_ids\": features[1][\"input_ids\"],\n",
    "            #                       \"attention_mask\": features[1][\"attention_mask\"]}]\n",
    "\n",
    "            # Prepare tokens\n",
    "            # kp_topic = modified_features[1][\"input_ids\"]\n",
    "            # kp_topic_tokens = modified_features[1][\"input_ids\"].tolist()[0]\n",
    "            # sep_token_index = kp_topic_tokens.index(50265) # <SEP> Token\n",
    "            # kp_tokens = kp_topic_tokens[:sep_token_index]\n",
    "            # topic_tokens = kp_topic_tokens[sep_token_index:]\n",
    "\n",
    "            # Prepare list of kps where a token is dropped\n",
    "            # new_kps = []\n",
    "            # for i in range(len(kp_tokens)):\n",
    "            #     dropped = kp_tokens[i]\n",
    "            #     new_kp = copy.deepcopy(kp_tokens)\n",
    "            #     new_kp.pop(i)\n",
    "            #     new_kps.append({\"kp\": new_kp, \"dropped\": dropped, \"index\": i})\n",
    "\n",
    "            # # Create dropped modified_features\n",
    "            # for new_kp in new_kps:\n",
    "            #     kp, dropped, index = new_kp.values()\n",
    "            #\n",
    "            #     # Modify sample itself\n",
    "            #     modified_features[1][\"input_ids\"] = torch.tensor(kp+topic_tokens)\n",
    "            #\n",
    "            #     # Modify attention mask\n",
    "            #     old_attention_mask = modified_features[1][\"attention_mask\"][0]\n",
    "            #     first_part = old_attention_mask[:index]\n",
    "            #     second_part = old_attention_mask[index+1:] # Here dropped index is excluded\n",
    "            #     new_attention_mask = torch.cat([first_part, second_part], dim=0)\n",
    "            #     new_attention_mask = new_attention_mask.view(1,len(new_attention_mask))\n",
    "            #     modified_features[1][\"attention_mask\"] = new_attention_mask\n",
    "            #\n",
    "            #     dropped_score = compute_entailment(loss_model, modified_features, labels)\n",
    "            #\n",
    "            #     dropped_scores.append({\"score\": dropped_score,\n",
    "            #                            \"dropped\": dropped,\n",
    "            #                            \"index\": index})\n",
    "            #     s = 0\n",
    "\n",
    "                # #Modify token embeddings\n",
    "                # old_token_embedding = features[1][\"token_embeddings\"][0]\n",
    "                # first_part = features[1][\"token_embeddings\"][0][:index]\n",
    "                # second_part = features[1][\"token_embeddings\"][0][index+1:]\n",
    "                # new_token_embedding = torch.cat([first_part, second_part])\n",
    "                # new_token_embedding = new_token_embedding.view(1, *new_token_embedding.size())\n",
    "                # features[1][\"token_embeddings\"] = new_token_embedding\n",
    "\n",
    "                # Modify sentence embeddings\n",
    "                # We can just drop the sentence embeddings, the model will infer this automatically"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}