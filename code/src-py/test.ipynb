{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models, util\n",
    "from nltk import word_tokenize\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import sbert_training\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch\n",
    "import sys\n",
    "import pickle\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "word_tokenizer = word_tokenize\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "repo_dir = \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code-2/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def save_with_pickle(path, data):\n",
    "    with open(path, \"wb\") as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_from_pickle(path):\n",
    "    data = None\n",
    "    with open(path, \"rb\") as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-24 20:25:54 - Load pretrained SentenceTransformer: /home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/model\n",
      "2022-01-24 20:25:55 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "def load_model():\n",
    "    try:\n",
    "        path = \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/model\"\n",
    "        model = SentenceTransformer(path)\n",
    "    except:\n",
    "        model = sbert_training.train_model('/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code-2/data/siamese-data/',\n",
    "                                           \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code-2/data/kpm_data\",\n",
    "                                           'dev',\n",
    "                                           \"/home/marcelbraasch/PycharmProjects/new_KPA/argmining-21-keypoint-analysis-sharedtask-code-2/code/siamese-models\",\n",
    "                                           'roberta-base',\n",
    "                                           model_suffix='contrastive-10-epochs',\n",
    "                                           data_file_suffix='contrastive',\n",
    "                                          num_epochs=10, max_seq_length=70, add_special_token=True, train_batch_size=32, loss='ContrastiveLoss')\n",
    "    return model\n",
    "\n",
    "model = load_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def load_closed_class_words():\n",
    "    path = \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code-2/code/src-py/closed_class_words.txt\"\n",
    "    data = []\n",
    "    with open(path, \"r\") as file:\n",
    "        for line in file:\n",
    "            data.extend(line.rstrip().split())\n",
    "    return data\n",
    "\n",
    "closed_class_words = load_closed_class_words()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def compute_entailment(arg, kp, model):\n",
    "    arg = model.encode(arg, show_progress_bar=False),\n",
    "    kp = model.encode(kp, show_progress_bar=False)\n",
    "    return float(util.pytorch_cos_sim(arg, kp))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def create_arg_kps_mapping(arguments_df, key_points_df):\n",
    "    mapping = {}\n",
    "    topics = arguments_df[\"topic\"].unique()\n",
    "    for topic in topics:\n",
    "        arguments = arguments_df.loc[arguments_df[\"topic\"] == topic][[\"argument\"]].drop_duplicates()\n",
    "        key_points = key_points_df.loc[key_points_df[\"topic\"] == topic][[\"key_point\"]].drop_duplicates()\n",
    "        map = pd.merge(arguments, key_points, how=\"cross\")\n",
    "        mapping[topic] = map\n",
    "    return mapping\n",
    "\n",
    "def load_kpm_data(model):\n",
    "    # path = \"gold_labels_and_prediction_scores.pkl\"\n",
    "    # try:\n",
    "    #     return load_from_pickle(path)\n",
    "    # except:\n",
    "    #     pass\n",
    "    data = defaultdict(dict)\n",
    "    for subset in [\"dev\"]:#, \"train\"]:\n",
    "\n",
    "        # Load files\n",
    "        arguments_file = repo_dir + f\"data/kpm_data/arguments_{subset}.csv\"\n",
    "        key_points_file = repo_dir + f\"data/kpm_data/key_points_{subset}.csv\"\n",
    "        labels_file = repo_dir + f\"data/kpm_data/labels_{subset}.csv\"\n",
    "        arguments_df = pd.read_csv(arguments_file)\n",
    "        key_points_df = pd.read_csv(key_points_file)\n",
    "        labels_df = pd.read_csv(labels_file)\n",
    "\n",
    "        # Get gold standard\n",
    "        positive_labels_df = labels_df.loc[labels_df[\"label\"] == 1]\n",
    "        gold_standard = pd.merge(positive_labels_df, key_points_df, how=\"inner\", on=\"key_point_id\")\n",
    "        gold_standard = pd.merge(gold_standard, arguments_df, how=\"inner\", on=[\"arg_id\",\"topic\", \"stance\"])\n",
    "        gold_standard = gold_standard.rename(columns={\"label\": \"score\"})\n",
    "        data[subset][\"gold_standard\"] = gold_standard\n",
    "\n",
    "        # Compute model scores\n",
    "        def compute_score_from(row):\n",
    "            argument = row[\"argument\"]\n",
    "            key_point = row[\"key_point\"]\n",
    "            return compute_entailment(argument, key_point, model)\n",
    "\n",
    "        mappings = []\n",
    "        arg_to_kps = create_arg_kps_mapping(arguments_df, key_points_df)\n",
    "        for topic, arg_kps_mapping in arg_to_kps.items():\n",
    "            arg_kps_mapping['score'] = arg_kps_mapping.apply(lambda row: compute_score_from(row), axis=1)\n",
    "            arg_kps_mapping['topic'] = topic\n",
    "            arg_kps_mapping = arg_kps_mapping[[\"topic\", \"argument\", \"key_point\", \"score\"]]\n",
    "            mappings.append(arg_kps_mapping)\n",
    "        predictions = pd.concat(mappings, axis=0)\n",
    "        data[subset][\"predictions\"] = predictions\n",
    "        save_with_pickle(path, data)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def tokenize_kp(row):\n",
    "    return word_tokenizer(row[\"key_point\"])\n",
    "\n",
    "def _leave_one_out(row):\n",
    "    words = row[\"key_point_words\"]\n",
    "    samples = [{\"dropped\": \"Reference\", \"new_kp\": row[\"key_point\"], \"score\": row[\"score\"]}]\n",
    "    for i in range(len(words)):\n",
    "        new_kp = copy.deepcopy(words)\n",
    "        dropped_word = new_kp.pop(i)\n",
    "        new_kp = \" \".join(new_kp)\n",
    "        new_score = compute_entailment(row[\"argument\"], new_kp, model)\n",
    "        samples.append({\"dropped\": dropped_word, \"new_kp\": new_kp, \"score\": new_score})\n",
    "    return samples\n",
    "\n",
    "def leave_one_out(model):\n",
    "    path = \"leave_one_out.pkl\"\n",
    "\n",
    "    try:\n",
    "        return load_from_pickle(path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Iterates over the kpm data dict and compute leave one out for each entry\n",
    "    dfs = load_kpm_data(model)\n",
    "    for gold_or_pred in dfs.values():\n",
    "        for df in gold_or_pred.values():\n",
    "            df[\"key_point_words\"] = df.apply(lambda row: tokenize_kp(row), axis=1)\n",
    "            df[\"leave_one_out\"] = df.apply(lambda row: _leave_one_out(row), axis=1)\n",
    "    save_with_pickle(path, dfs)\n",
    "\n",
    "    return dfs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def _argument_leave_one_out_(tokens, words, generate_ngrams=False):\n",
    "\n",
    "    samples = []\n",
    "    random_choices = []\n",
    "    random_amount = 30\n",
    "    counter = 0\n",
    "    tries = 0\n",
    "\n",
    "    # Create dropped argument realizations of ngrams\n",
    "    if generate_ngrams:\n",
    "        for ngram in range(1,4):\n",
    "            for i in range(len(tokens)-ngram+1):\n",
    "                new_arg = copy.deepcopy(tokens)\n",
    "                dropped_words = [new_arg.pop(i) for _ in range(ngram)]\n",
    "                new_arg = \" \".join(new_arg)\n",
    "                samples.append({\"dropped\": dropped_words,\n",
    "                                \"new_arg\": new_arg,\n",
    "                                \"ngram\": f\"{ngram}\"})\n",
    "\n",
    "    # Drop 2 to 4 random words 10 times excluding functional words\n",
    "    lexical_mask = [1 if x not in closed_class_words else 0 for x in tokens]\n",
    "    lexical_amount = lexical_mask.count(1)\n",
    "    lexical_indices = [i for i, x in enumerate(lexical_mask) if x]\n",
    "    if lexical_amount <= 2: return samples\n",
    "    while counter != random_amount:\n",
    "        amount = random.randrange(2, 4)\n",
    "        random_choice = {j for j in random.choices(lexical_indices, k=amount)}\n",
    "        if len(random_choice) == amount:\n",
    "            if random_choice not in random_choices:\n",
    "                random_choices.append(random_choice)\n",
    "                counter += 1\n",
    "        tries += 1\n",
    "        if tries == 250:\n",
    "            break\n",
    "\n",
    "    # We gather the collection first before we process it\n",
    "    # to make sure our selection is unique\n",
    "    s = 0\n",
    "    for random_choice in random_choices:\n",
    "        random_choice = list(random_choice)\n",
    "        random_choice.sort(reverse=True)\n",
    "        new_arg = copy.deepcopy(tokens)\n",
    "        dropped_words = [new_arg.pop(index) for index in random_choice]\n",
    "        sample = {\"dropped\": dropped_words,\n",
    "                  \"new_arg\": new_arg,\n",
    "                  \"ngram\": f\"random_{len(random_choice)}\",\n",
    "                  \"indices\": random_choice}\n",
    "        samples.append(sample)\n",
    "\n",
    "    return samples\n",
    "\n",
    "def load_mappings():\n",
    "    path = \"arg_to_dropped_mapping.pkl\"\n",
    "    try:\n",
    "        return load_from_pickle(path)\n",
    "    except:\n",
    "        pass\n",
    "    mappings = {argument:_argument_leave_one_out_(word_tokenizer(argument), argument)\n",
    "                for argument in arguments}\n",
    "    save_with_pickle(path, mappings)\n",
    "    return mappings\n",
    "\n",
    "# Create leave one out for the arguments\n",
    "n = 5\n",
    "k = 0\n",
    "leave_one_out_path = \"./Leave One Out\"\n",
    "data_path = \"./gold_labels_and_prediction_scores.pkl\"\n",
    "column_names = [\"dropped\", \"new_arg\", \"ngram\", \"indices\"]\n",
    "data = load_from_pickle(data_path)\n",
    "current = data[\"dev\"][\"predictions\"]\n",
    "arguments = current[\"argument\"].unique()\n",
    "topics = current[\"topic\"].unique()\n",
    "mappings = load_mappings()\n",
    "for topic in topics:\n",
    "    key_points = current.loc[current['topic'] == topic][\"key_point\"].unique()\n",
    "    for argument in arguments:\n",
    "        top_n = current.loc[current[\"argument\"]==argument] \\\n",
    "                       .sort_values(by=[\"score\"], ascending=False) \\\n",
    "                       .head(n)\n",
    "        new_args = pd.DataFrame.from_dict(mappings[argument])\n",
    "        new_args[\"new_arg\"] = new_args.apply(lambda row: \" \".join(row[\"new_arg\"]), axis=1)\n",
    "        new_args.rename(columns={\"score\": \"reference_score\"})\n",
    "        loo_curr_arg = pd.merge(top_n, new_args, how=\"cross\")\n",
    "        loo_curr_arg[\"dropped_score\"] = loo_curr_arg.apply(lambda row: compute_entailment(row[\"new_arg\"], row[\"key_point\"], model), axis=1)\n",
    "        loo_curr_arg[\"dropped_score_normalized\"] = loo_curr_arg.apply(lambda row: row[\"dropped_score\"] / len(row[\"indices\"]), axis=1)\n",
    "        loo_curr_arg[\"diff\"] = loo_curr_arg[\"score\"] - loo_curr_arg[\"dropped_score\"]\n",
    "        loo_curr_arg[\"diff_normalized\"] = loo_curr_arg.apply(lambda row: row[\"diff\"] / len(row[\"indices\"]), axis=1)\n",
    "        save_with_pickle(f\"./Leave One Out/arg_{k}_leave_one_out.pkl\", loo_curr_arg)\n",
    "        k += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# cmap = plt.cm.get_cmap('YlOrBr')\n",
    "#\n",
    "# s = 0\n",
    "# counter = 0\n",
    "# for sample in best_arg_kps.iterrows():\n",
    "#     leave_one_out_sample = sample[1][\"leave_one_out\"]\n",
    "#\n",
    "#     plt.text(0,1.5,f\"Argument: {sample[1]['argument']}\", fontsize=20)\n",
    "#     plt.text(0,1.4,f\"Key point: {sample[1]['key_point']}\", fontsize=20)\n",
    "#\n",
    "#     _max = max([leave_one_out_sample[i][\"score\"]\n",
    "#                for i in range(1, len(leave_one_out_sample))])\n",
    "#\n",
    "#     y_coord = 1.2\n",
    "#     for i in range(1, len(leave_one_out_sample)):\n",
    "#         word = leave_one_out_sample[i][\"dropped\"]\n",
    "#         importance = leave_one_out_sample[i][\"score\"] #- _max\n",
    "#         plt.text(0,y_coord,f\"{word} ({importance})\", fontsize=20, backgroundcolor=cmap(importance))\n",
    "#         y_coord -= 0.1\n",
    "#     plt.axis('off')\n",
    "#     # _in = input()\n",
    "#     # if _in == \"exit\":\n",
    "#     break\n",
    "#     # plt.figure().clear()\n",
    "#     # plt.close()\n",
    "#     # plt.cla()\n",
    "#     # plt.clf()\n",
    "#\n",
    "#     # Drop words in argument\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}