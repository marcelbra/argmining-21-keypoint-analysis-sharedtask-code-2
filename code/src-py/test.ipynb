{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "\n",
    "- Import model\n",
    "    Import the trained model instead of training from scratch\n",
    "    - See cell 3\n",
    "    - The basic idea is:\n",
    "        - initialize the model as it was trained, in sbert_training the definition can be found\n",
    "        - load the weights into the model (by whichever means)\n",
    "        - The trained model is here: https://drive.google.com/drive/folders/1qgGdoNMUcyQivTtu5udzGcQB8SFgxm-M?usp=sharing\n",
    "\n",
    "- Leave-one-out\n",
    "    Extend the method / dataloader with all instead of only the dummy sample\n",
    "    - The dev data can be found in /new_KPA/argmining-21-keypoint-analysis-sharedtask-code/data/kpm_data\n",
    "    - There could be two ways to approach this:\n",
    "        - Interpret the gold standard:\n",
    "            - Iterate over kps in key_points_dev.csv and grab the respective argument from arguments_dev.csv\n",
    "        - Let the model decide what is the right arg\n",
    "            - Iterate over all args, computer score with each kp and save argmax\n",
    "    - What needs to be added is for each InputExample save the word we dropped so we can access it during\n",
    "      entailment computing. For this copy InputExample from SentenceBert and modify class, save word to later access\n",
    "\n",
    "- SHAP\n",
    "    - TODO\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import *\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, losses, models, util\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import sys\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "sys.path.insert(0, \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code-2/code/src-py\")\n",
    "import sbert_training\n",
    "work_tokenizer = word_tokenize\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "repo_dir = \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code-2/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "#!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = sbert_training.train_model('/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code-2/data/siamese-data/',\n",
    "                                   \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code-2/data/kpm_data\",\n",
    "                                   'dev',\n",
    "                                   \"/home/marcelbraasch/PycharmProjects/new_KPA/argmining-21-keypoint-analysis-sharedtask-code-2/code/siamese-models\",\n",
    "                                   'roberta-base',\n",
    "                                   model_suffix='contrastive-10-epochs',\n",
    "                                   data_file_suffix='contrastive',\n",
    "                                   num_epochs=10, max_seq_length=70, add_special_token=True, train_batch_size=32, loss='ContrastiveLoss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# def load_model():\n",
    "#     max_seq_length = 70\n",
    "#     model_name = 'distilbert-base-uncased'\n",
    "#     word_embedding_model = models.Transformer(model_name)\n",
    "#     word_embedding_model.max_seq_length = max_seq_length\n",
    "#     word_embedding_model.tokenizer.add_tokens(['<SEP>'], special_tokens=True)\n",
    "#     word_embedding_model.auto_model.resize_token_embeddings(len(word_embedding_model.tokenizer))\n",
    "#     pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "#                                    pooling_mode_mean_tokens=True,\n",
    "#                                    pooling_mode_cls_token=False,\n",
    "#                                    pooling_mode_max_tokens=False)\n",
    "#     model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "#     return model\n",
    "\n",
    "# config = BertConfig.from_json_file(\"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/model/config.json\")\n",
    "# model = TFBertModel.from_pretrained('/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/model/my_pytorch_model.bin', from_pt=True, config=config)\n",
    "\n",
    "# path = \"./siamese_state_dict_2.pt\"\n",
    "# state_dict = torch.load(path)[\"state_dict\"]\n",
    "# model = load_model()\n",
    "# model.load_state_dict(state_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_5075/3534697388.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m \u001B[0mload_kpm_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_5075/3534697388.py\u001B[0m in \u001B[0;36mload_kpm_data\u001B[0;34m()\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mgold_standard\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgold_standard\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"argument\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"key_point\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msubset\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgold_standard\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0mload_kpm_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_5075/3534697388.py\u001B[0m in \u001B[0;36mload_kpm_data\u001B[0;34m()\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mgold_standard\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgold_standard\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"argument\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"key_point\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msubset\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgold_standard\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0mload_kpm_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001B[0m in \u001B[0;36mtrace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    878\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    879\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mplugin_stop\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 880\u001B[0;31m                     \u001B[0mstopped_on_plugin\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mplugin_manager\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmain_debugger\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_info\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep_cmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    881\u001B[0m                 \u001B[0;32melif\u001B[0m \u001B[0mstop\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    882\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mis_line\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\u001B[0m in \u001B[0;36mstop\u001B[0;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[1;32m    163\u001B[0m         \u001B[0mframe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msuspend_jupyter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmain_debugger\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep_cmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    164\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 165\u001B[0;31m             \u001B[0mmain_debugger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    166\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1146\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1160\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1162\u001B[0;31m                 \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def load_kpm_data():\n",
    "    data = {}\n",
    "    for subset in [\"dev\", \"train\"]:\n",
    "        arguments_file = repo_dir + f\"data/kpm_data/arguments_{subset}.csv\"\n",
    "        key_points_file = repo_dir + f\"data/kpm_data/key_points_{subset}.csv\"\n",
    "        labels_file = repo_dir + f\"data/kpm_data/labels_{subset}.csv\"\n",
    "        arguments_df = pd.read_csv(arguments_file)\n",
    "        key_points_df = pd.read_csv(key_points_file)\n",
    "        labels_df = pd.read_csv(labels_file)\n",
    "        positive_labels_df = labels_df.loc[labels_df[\"label\"] == 1]\n",
    "        gold_standard = pd.merge(positive_labels_df, key_points_df, how=\"inner\", on=\"key_point_id\")\n",
    "        gold_standard = pd.merge(gold_standard, arguments_df, how=\"inner\", on=\"arg_id\")\n",
    "        gold_standard = gold_standard[[\"argument\", \"key_point\"]]\n",
    "        data[subset] = gold_standard\n",
    "    return data\n",
    "\n",
    "load_kpm_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "class InputExample:\n",
    "\n",
    "    def __init__(self,\n",
    "                 arg: str = None,\n",
    "                 kp: str = None,\n",
    "                 label: Union[int, float] = 0,\n",
    "                 dropped_word: str = None\n",
    "                 ):\n",
    "\n",
    "        self.arg = arg\n",
    "        self.kp = kp\n",
    "        self.label = label\n",
    "        self.dropped_word = dropped_word\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<InputExample> label: {}, texts: {}\".format(str(self.label), \"; \".join(self.texts))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_5075/1801623537.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0msamples\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 32\u001B[0;31m \u001B[0mget_data_for_leave_one_out\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_5075/1801623537.py\u001B[0m in \u001B[0;36mget_data_for_leave_one_out\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mFor\u001B[0m \u001B[0meach\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mkp\u001B[0m \u001B[0mpair\u001B[0m \u001B[0mwe\u001B[0m \u001B[0mcreate\u001B[0m \u001B[0mno_of_words_in_kp\u001B[0m \u001B[0mInputExamples\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \"\"\"\n\u001B[0;32m----> 6\u001B[0;31m     \u001B[0mdfs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mload_kpm_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m     \u001B[0msamples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0;31m# Here all the data should be loaded instead of only 1 test sample\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_5075/2967644879.py\u001B[0m in \u001B[0;36mload_kpm_data\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mkey_points_file\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrepo_dir\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34mf\"data/kpm_data/key_points_{subset}.csv\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mlabels_file\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrepo_dir\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34mf\"data/kpm_data/labels_{subset}.csv\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m         \u001B[0marguments_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marguments_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m         \u001B[0mkey_points_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey_points_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0mlabels_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_5075/2967644879.py\u001B[0m in \u001B[0;36mload_kpm_data\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mkey_points_file\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrepo_dir\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34mf\"data/kpm_data/key_points_{subset}.csv\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mlabels_file\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrepo_dir\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34mf\"data/kpm_data/labels_{subset}.csv\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m         \u001B[0marguments_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marguments_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m         \u001B[0mkey_points_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey_points_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0mlabels_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001B[0m in \u001B[0;36mtrace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    745\u001B[0m                 \u001B[0;31m# if thread has a suspend flag, we suspend with a busy wait\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    746\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0minfo\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpydev_state\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mSTATE_SUSPEND\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 747\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    748\u001B[0m                     \u001B[0;31m# No need to reset frame.f_trace to keep the same trace function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    749\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrace_dispatch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 144\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m     \u001B[0;31m# IFDEF CYTHON\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1146\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1160\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1162\u001B[0;31m                 \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def get_data_for_leave_one_out():\n",
    "    \"\"\"\n",
    "    Creates a nested list of data.\n",
    "    For each arg-kp pair we create no_of_words_in_kp InputExamples.\n",
    "    \"\"\"\n",
    "    dfs = load_kpm_data()\n",
    "    # TODO: iterate of dfs and create examples\n",
    "    for _ in range(1):\n",
    "        topic = \"We should abandon the use of school uniform\"\n",
    "        arg = \"A real education is about giving students the tools to learn, think, and express themselves; dictating to them what to wear sends a strong message that we don't trust them to think on their own.\"\n",
    "        kp = \"School uniform is harming the student's self expression\"\n",
    "        label = 1\n",
    "        sample = [InputExample(arg=arg,\n",
    "                               kp= kp + \" <SEP> \" + topic,\n",
    "                               label=label,\n",
    "                               dropped_word=\"Reference\")]\n",
    "        words = work_tokenizer(kp)\n",
    "        for i in range(len(words)):\n",
    "            new_kp = copy.deepcopy(words)\n",
    "            new_kp.pop(i)\n",
    "            new_kp_topic = \" \".join(new_kp)\n",
    "            dropped_word = words[i]\n",
    "            sample.append(InputExample(arg=arg,\n",
    "                                       kp=new_kp_topic,\n",
    "                                       label=label,\n",
    "                                       dropped_word=dropped_word))\n",
    "        samples.append(sample)\n",
    "\n",
    "    return samples\n",
    "\n",
    "get_data_for_leave_one_out()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def compute_entailment(example, model):\n",
    "    arg = model.encode(example.arg, show_progress_bar=False),\n",
    "    kp = model.encode(example.kp, show_progress_bar=False)\n",
    "    return float(util.pytorch_cos_sim(arg, kp))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropped_word': 'Reference', 'score': 0.7359759211540222}\n",
      "{'dropped_word': 'School', 'score': 0.7497543096542358}\n",
      "{'dropped_word': 'uniform', 'score': 0.8354253768920898}\n",
      "{'dropped_word': 'is', 'score': 0.7495176792144775}\n",
      "{'dropped_word': 'harming', 'score': 0.7948923110961914}\n",
      "{'dropped_word': 'the', 'score': 0.7566003799438477}\n",
      "{'dropped_word': 'student', 'score': 0.7206475734710693}\n",
      "{'dropped_word': \"'s\", 'score': 0.7695661187171936}\n",
      "{'dropped_word': 'self', 'score': 0.7628238797187805}\n",
      "{'dropped_word': 'expression', 'score': 0.5826172828674316}\n"
     ]
    }
   ],
   "source": [
    "def leave_one_out(model, data):\n",
    "    results = []\n",
    "    for sentences in samples:\n",
    "        result = []\n",
    "        for i, example in enumerate(sentences):\n",
    "            r = {\"dropped_word\": example.dropped_word,\n",
    "                 \"score\": compute_entailment(example, model)}\n",
    "            result.append(r)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "samples = get_data_for_leave_one_out()\n",
    "results = leave_one_out(model, samples)\n",
    "print(*(results[0]), sep=\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "############################################################\n",
    "############################################################\n",
    "################# CODE GRAVEYARD ###########################\n",
    "############################################################\n",
    "############################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# modified_features = [{\"input_ids\": features[0][\"input_ids\"],\n",
    "#                       \"attention_mask\": features[0][\"attention_mask\"]},\n",
    "#                      {\"input_ids\": features[1][\"input_ids\"],\n",
    "#                       \"attention_mask\": features[1][\"attention_mask\"]}]\n",
    "\n",
    "# Prepare tokens\n",
    "# kp_topic = modified_features[1][\"input_ids\"]\n",
    "# kp_topic_tokens = modified_features[1][\"input_ids\"].tolist()[0]\n",
    "# sep_token_index = kp_topic_tokens.index(50265) # <SEP> Token\n",
    "# kp_tokens = kp_topic_tokens[:sep_token_index]\n",
    "# topic_tokens = kp_topic_tokens[sep_token_index:]\n",
    "\n",
    "# Prepare list of kps where a token is dropped\n",
    "# new_kps = []\n",
    "# for i in range(len(kp_tokens)):\n",
    "#     dropped = kp_tokens[i]\n",
    "#     new_kp = copy.deepcopy(kp_tokens)\n",
    "#     new_kp.pop(i)\n",
    "#     new_kps.append({\"kp\": new_kp, \"dropped\": dropped, \"index\": i})\n",
    "\n",
    "# # Create dropped modified_features\n",
    "# for new_kp in new_kps:\n",
    "#     kp, dropped, index = new_kp.values()\n",
    "#\n",
    "#     # Modify sample itself\n",
    "#     modified_features[1][\"input_ids\"] = torch.tensor(kp+topic_tokens)\n",
    "#\n",
    "#     # Modify attention mask\n",
    "#     old_attention_mask = modified_features[1][\"attention_mask\"][0]\n",
    "#     first_part = old_attention_mask[:index]\n",
    "#     second_part = old_attention_mask[index+1:] # Here dropped index is excluded\n",
    "#     new_attention_mask = torch.cat([first_part, second_part], dim=0)\n",
    "#     new_attention_mask = new_attention_mask.view(1,len(new_attention_mask))\n",
    "#     modified_features[1][\"attention_mask\"] = new_attention_mask\n",
    "#\n",
    "#     dropped_score = compute_entailment(loss_model, modified_features, labels)\n",
    "#\n",
    "#     dropped_scores.append({\"score\": dropped_score,\n",
    "#                            \"dropped\": dropped,\n",
    "#                            \"index\": index})\n",
    "#     s = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def get_backbone_model_and_tokenizer():\n",
    "#     name = 'roberta-base'\n",
    "#     backbone = models.Transformer(name)\n",
    "#     backbone.max_seq_length = 70\n",
    "#     backbone.tokenizer.add_tokens(['<SEP>'], special_tokens=True)\n",
    "#     backbone.auto_model.resize_token_embeddings(len(backbone.tokenizer))\n",
    "#     return backbone, backbone.tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #Modify token embeddings\n",
    "# old_token_embedding = features[1][\"token_embeddings\"][0]\n",
    "# first_part = features[1][\"token_embeddings\"][0][:index]\n",
    "# second_part = features[1][\"token_embeddings\"][0][index+1:]\n",
    "# new_token_embedding = torch.cat([first_part, second_part])\n",
    "# new_token_embedding = new_token_embedding.view(1, *new_token_embedding.size())\n",
    "# features[1][\"token_embeddings\"] = new_token_embedding\n",
    "\n",
    "# Modify sentence embeddings\n",
    "# We can just drop the sentence embeddings, the model will infer this automatically"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# def get_dataloader(examples, model):\n",
    "#     dataloader = DataLoader(examples, shuffle=False, batch_size=1)\n",
    "#     dataloader.collate_fn = model.smart_batching_collate\n",
    "#     return iter(dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# def get_dataloaders_for_leave_one_out(data, model):\n",
    "#     dataloaders = []\n",
    "#     for sample in data:\n",
    "#         # sample has no_of_words_in_kp examples in it\n",
    "#         dataloader = DataLoader(sample, shuffle=False, batch_size=1)\n",
    "#         #dataloader.collate_fn = model.smart_batching_collate\n",
    "#         dataloaders.append(dataloader)\n",
    "#     return dataloaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def prepare_model_for_inference(model):\n",
    "    model = losses.ContrastiveLoss(model)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def compute_entailment(model, features, labels):\n",
    "#     return float((1 - model(features, labels)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}