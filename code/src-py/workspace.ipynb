{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models, util\n",
    "from nltk import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import chain, combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import sbert_training\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "from tqdm.notebook import tqdm_notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def save_with_pickle(path, data):\n",
    "    with open(path, \"wb\") as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_from_pickle(path):\n",
    "    data = None\n",
    "    with open(path, \"rb\") as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-07 22:59:58 - Load pretrained SentenceTransformer: /home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/model\n",
      "2022-02-07 22:59:59 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "word_tokenizer = word_tokenize\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "repo_dir = \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code-2/\"\n",
    "model_path = \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/model\"\n",
    "model = SentenceTransformer(model_path)\n",
    "closed_class_words_path = \"./Data/closed.pkl\"\n",
    "closed_class_words = load_from_pickle(closed_class_words_path)\n",
    "\n",
    "# Load data, unique topics and arguments\n",
    "mappings_path = \"./Data/arg_to_dropped_mapping.pkl\"\n",
    "data_path = \"./Data/gold_labels_and_prediction_scores.pkl\"\n",
    "word_importance_path = \"./Data/word_importance.pkl\"\n",
    "leave_one_out_path = \"./Data/leave_one_out.pkl\"\n",
    "\n",
    "data = load_from_pickle(data_path)\n",
    "word_importances = load_from_pickle(word_importance_path)\n",
    "predictions = data[\"dev\"][\"predictions\"]\n",
    "arguments = predictions[\"argument\"].unique()\n",
    "topics = predictions[\"topic\"].unique()\n",
    "key_points = predictions[\"key_point\"].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def compute_score(arg, kp, model):\n",
    "    arg = model.encode(arg, show_progress_bar=False),\n",
    "    kp = model.encode(kp, show_progress_bar=False)\n",
    "    return float(util.pytorch_cos_sim(arg, kp))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def create_gold_labels_and_prediction_scores(model, path):\n",
    "\n",
    "    data = defaultdict(dict)\n",
    "    for subset in [\"dev\", \"train\"]:\n",
    "\n",
    "        # Load files\n",
    "        arguments_file = repo_dir + f\"data/kpm_data/arguments_{subset}.csv\"\n",
    "        key_points_file = repo_dir + f\"data/kpm_data/key_points_{subset}.csv\"\n",
    "        labels_file = repo_dir + f\"data/kpm_data/labels_{subset}.csv\"\n",
    "        arguments_df = pd.read_csv(arguments_file)\n",
    "        key_points_df = pd.read_csv(key_points_file)\n",
    "        labels_df = pd.read_csv(labels_file)\n",
    "\n",
    "        # Get gold standard\n",
    "        positive_labels_df = labels_df.loc[labels_df[\"label\"] == 1]\n",
    "        gold_standard = pd.merge(positive_labels_df, key_points_df, how=\"inner\", on=\"key_point_id\")\n",
    "        gold_standard = pd.merge(gold_standard, arguments_df, how=\"inner\", on=[\"arg_id\",\"topic\", \"stance\"])\n",
    "        gold_standard = gold_standard.rename(columns={\"label\": \"score\"})\n",
    "        data[subset][\"gold_standard\"] = gold_standard\n",
    "        \n",
    "        # Within a topic map every key-point to every argument\n",
    "        arg_to_kps = {topic: pd.merge(arguments_df.loc[arguments_df[\"topic\"] == topic][[\"argument\"]].drop_duplicates(),\n",
    "                              key_points_df.loc[key_points_df[\"topic\"] == topic][[\"key_point\"]].drop_duplicates(),\n",
    "                              how=\"cross\") for topic in arguments_df[\"topic\"].unique()}\n",
    "\n",
    "        # Create predictions\n",
    "        mappings = []\n",
    "        for topic, arg_kps_mapping in arg_to_kps.items():\n",
    "            arg_kps_mapping['score'] = arg_kps_mapping.apply(lambda row: compute_score(row[\"argument\"], row[\"key_point\"], model), axis=1)\n",
    "            arg_kps_mapping['topic'] = topic\n",
    "            arg_kps_mapping = arg_kps_mapping[[\"topic\", \"argument\", \"key_point\", \"score\"]]\n",
    "            mappings.append(arg_kps_mapping)\n",
    "        predictions = pd.concat(mappings, axis=0)\n",
    "        data[subset][\"predictions\"] = predictions\n",
    "\n",
    "    save_with_pickle(path, data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n1. Analyze per kp their respective argument and check how similar the arguments are\\n2. Analyze for how many arg-kp pairs the most prevalent words are occuring in both\\n3. Analyze bad predictions to maybe understand why theyre wrong, or what made the model do the presumably right, but incorrect, prediction\\n'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Analyze per kp their respective argument and check how similar the arguments are\n",
    "2. Analyze for how many arg-kp pairs the most prevalent words are occuring in both\n",
    "3. Analyze bad predictions to maybe understand why theyre wrong, or what made the model do the presumably right, but incorrect, prediction\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))\n",
    "\n",
    "def _create_dropped_combinations(argument, drop_size=4):\n",
    "    tokens = word_tokenizer(argument)\n",
    "    samples = []\n",
    "    lexical_mask = [1 if x not in closed_class_words else 0 for x in tokens]\n",
    "    lexical_indices = [i for i, x in enumerate(lexical_mask) if x]\n",
    "    lexical_indices_combinations = powerset(lexical_indices)\n",
    "    lexical_indices_combinations = [x for x in lexical_indices_combinations\n",
    "                                    if len(x)<=drop_size][1:]\n",
    "    for combination in lexical_indices_combinations:\n",
    "        combination = list(combination)\n",
    "        combination.sort(reverse=True)\n",
    "        new_arg = copy.deepcopy(tokens)\n",
    "        dropped_words = [new_arg.pop(index) for index in combination]\n",
    "        sample = {\"dropped\": dropped_words,\n",
    "                  \"new_arg\": \" \".join(new_arg),\n",
    "                  \"amount_dropped\": len(combination),\n",
    "                  \"indices\": combination}\n",
    "        samples.append(sample)\n",
    "    return samples\n",
    "\n",
    "def create_dropped_combinations(arguments):\n",
    "    return {argument:_create_dropped_combinations(argument)\n",
    "            for argument in tqdm_notebook(arguments)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class Importance:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.counter = 0\n",
    "        self.scores = []\n",
    "\n",
    "    def update(self, score):\n",
    "        self.counter += 1\n",
    "        self.scores.append(score)\n",
    "\n",
    "    def get(self):\n",
    "        return sum(self.scores) / self.counter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def compute_word_importance(argument, key_point, arg_to_dropped, model):\n",
    "    reference = compute_score(argument, key_point, model)\n",
    "    dropped = arg_to_dropped[argument][:750]\n",
    "    word_to_importance = defaultdict(Importance)\n",
    "    for example in tqdm_notebook(dropped):\n",
    "        dropped_words, new_argument, amount_dropped, indices = example.values()\n",
    "        new_score = compute_score(new_argument, key_point, model)\n",
    "        difference = reference - new_score\n",
    "        for word in dropped_words:\n",
    "            word_to_importance[word].update(difference)\n",
    "    return {word: importance.get() for word, importance in word_to_importance.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def compute_word_importances_of_all_arg_kps():\n",
    "        args_kps = predictions\n",
    "        arg_to_dropped = create_dropped_combinations(args_kps[\"argument\"].unique())\n",
    "        args_kps[\"important_words\"] = args_kps.apply(lambda row: compute_word_importance(row[\"argument\"], row[\"key_point\"], arg_to_dropped, model), axis=1)\n",
    "        save_with_pickle(\"word_importance.pkl\", args_kps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def create_leave_one_out_for_args():\n",
    "    loo = []\n",
    "    for topic in topics:\n",
    "        # Get all unique key points for a specific topic\n",
    "        key_points = predictions.loc[predictions['topic'] == topic][\"key_point\"].unique()\n",
    "        for argument in tqdm_notebook(arguments):\n",
    "\n",
    "            # Get the top n key points corresponding to current argument\n",
    "            top_n = word_importances.loc[word_importances[\"argument\"]==argument] \\\n",
    "                                    .sort_values(by=[\"score\"], ascending=False).head(5)\n",
    "            df = pd.DataFrame()\n",
    "            for i, row in enumerate(top_n.iterrows()):\n",
    "                topic, argument, key_point, score, importances = row[1]\n",
    "                # Extract word importance scores\n",
    "                importances = pd.DataFrame.from_dict({x:[y] for x,y in importances.items()}) \\\n",
    "                                .transpose().reset_index() \\\n",
    "                                .rename(columns={\"index\":f\"words_{i}\", 0:f\"importance_{i}\"})\n",
    "                importances.insert(0, \"score\", score)\n",
    "                importances.insert(0, \"key_point\", key_point)\n",
    "                df = pd.concat((df, importances), axis=1)\n",
    "            df.insert(0, 'argument', argument)\n",
    "            loo.append(df)\n",
    "    save_with_pickle(\"./Data/leave_one_out.pkl\", loo)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def create_kp_to_its_args():\n",
    "    argmax_kps = word_importances[word_importances.groupby(['topic',\"argument\"])['score'].transform(max) == word_importances['score']]\n",
    "    saved_word_rankings = {}\n",
    "    for key_point in key_points:\n",
    "        current_kp = argmax_kps.loc[argmax_kps[\"key_point\"]==key_point]\n",
    "        counter = defaultdict(int)\n",
    "        for mapping in current_kp[\"important_words\"]:\n",
    "            top_5 = {k:v for i, (k,v) in\n",
    "                     enumerate(sorted(mapping.items(), key=lambda x: x[1], reverse=True))\n",
    "                     if i <= 5}\n",
    "            for word in top_5.keys():\n",
    "                counter[word] += 1\n",
    "        counter = {k:v for i,(k,v) in enumerate(sorted(counter.items(), key=lambda x: x[1], reverse=True)) if i <= 10}\n",
    "        saved_word_rankings[key_point] = counter\n",
    "    return saved_word_rankings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Part 1: Leave one out\n",
    "loo = load_from_pickle(leave_one_out_path)\n",
    "\n",
    "if False:\n",
    "    for i, sheet in enumerate(loo):\n",
    "        sheet.to_excel(f\"./Results/LOO/sheet_{i}.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Part 2: key-point argument mappoing\n",
    "if False:\n",
    "    kptia = create_kp_to_its_args()\n",
    "    for kp, important_words in kptia.items():\n",
    "        s = f\"{kp}\\n\"\n",
    "        for word, occurence in important_words.items():\n",
    "            s += f\"{word}\\t{occurence}\\n\"\n",
    "        s += \"\\n\"\n",
    "        with open(\"kps_importances.txt\", \"a\") as f:\n",
    "            f.write(s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "def get_stuff(l):\n",
    "    new_df = pd.DataFrame()\n",
    "    argument = l.iloc[:,0][0]\n",
    "    scores = pd.concat([(l.iloc[:,(4*i)]) for i in range(1,6)], axis=1)\n",
    "    words = l.iloc[:,3]\n",
    "    df = pd.concat((words,scores),axis=1)\n",
    "    kps = [x[1] for x in [l.iloc[:,(4*i-3)] for i in range(1,6)]]\n",
    "    df = df.rename(columns={f\"importance_{i}\":kps[i] for i in range(len(kps))})\n",
    "    df = df.rename(columns={\"words_0\":\"words\"})\n",
    "    topic = list(predictions.loc[predictions[\"key_point\"]==kps[0]][\"topic\"])[0]\n",
    "    reference_scores = [x[1] for x in [l.iloc[:,(4*i-2)] for i in range(1,6)]]\n",
    "    return topic, argument, df, reference_scores\n",
    "\n",
    "# for i in tqdm_notebook(range(len(loo))):\n",
    "#     topic, argument, df, reference_scores = get_stuff(loo[i])\n",
    "#     name_excel = f\"./Results/LOO/sheet_{i}.xlsx\"\n",
    "#     name_metad = f\"./Results/LOO/sheet_{i}.txt\"\n",
    "#     if i in [0, 1283, 1690, 3306]:\n",
    "#         print(reference_scores)\n",
    "    # df.to_excel(name_excel)\n",
    "    # with open(name_metad, \"w\") as f:\n",
    "    #     f.write(f\"Topic: {topic}\\nArgument: {argument}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-07 23:35:13 - Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_38339/938663359.py\", line 1, in <module>\n",
      "    s = 0\n",
      "  File \"/tmp/ipykernel_38339/938663359.py\", line 1, in <module>\n",
      "    s = 0\n",
      "  File \"/home/marcelbraasch/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\", line 747, in trace_dispatch\n",
      "    self.do_wait_suspend(thread, frame, event, arg)\n",
      "  File \"/home/marcelbraasch/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\", line 144, in do_wait_suspend\n",
      "    self._args[0].do_wait_suspend(*args, **kwargs)\n",
      "  File \"/home/marcelbraasch/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/pydevd.py\", line 1147, in do_wait_suspend\n",
      "    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)\n",
      "  File \"/home/marcelbraasch/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/pydevd.py\", line 1162, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/marcelbraasch/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 692, in getsourcefile\n",
      "    def getsourcefile(object):\n",
      "KeyboardInterrupt\n",
      "2022-02-07 23:35:13 - \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_38339/938663359.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_38339/938663359.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001B[0m in \u001B[0;36mtrace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    746\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0minfo\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpydev_state\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mSTATE_SUSPEND\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 747\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    748\u001B[0m                     \u001B[0;31m# No need to reset frame.f_trace to keep the same trace function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 144\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1146\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1162\u001B[0;31m                 \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2076\u001B[0m                         \u001B[0;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2077\u001B[0;31m                         \u001B[0mstb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2078\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2077\u001B[0m                         \u001B[0mstb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2078\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2079\u001B[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[0m\u001B[1;32m   2080\u001B[0m                                             value, tb, tb_offset=tb_offset)\n\u001B[1;32m   2081\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1365\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1367\u001B[0;31m         return FormattedTB.structured_traceback(\n\u001B[0m\u001B[1;32m   1368\u001B[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[1;32m   1369\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1265\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose_modes\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1266\u001B[0m             \u001B[0;31m# Verbose modes need a full traceback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1267\u001B[0;31m             return VerboseTB.structured_traceback(\n\u001B[0m\u001B[1;32m   1268\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1269\u001B[0m             )\n",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1122\u001B[0m         \u001B[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1123\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1124\u001B[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[0m\u001B[1;32m   1125\u001B[0m                                                                tb_offset)\n\u001B[1;32m   1126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1081\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1082\u001B[0;31m         \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1083\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1084\u001B[0m         \u001B[0mframes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/argmining-21-keypoint-analysis-sharedtask-code/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[0;34m(etype, value, records)\u001B[0m\n\u001B[1;32m    380\u001B[0m     \u001B[0;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    381\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 382\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    383\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    384\u001B[0m     \u001B[0;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "s = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}